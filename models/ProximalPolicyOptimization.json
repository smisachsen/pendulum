{"agent": "ppo", "states": {"type": "float", "shape": [2]}, "actions": {"type": "float", "shape": [1], "min_value": -1.0, "max_value": 1.0}, "max_episode_timesteps": 200, "batch_size": 20, "network": [{"type": "dense", "size": 512, "activation": "tanh"}, {"type": "dense", "size": 512, "activation": "tanh"}], "use_beta_distribution": true, "memory": null, "update_frequency": 20, "learning_rate": 0.001, "subsampling_fraction": 0.33, "optimization_steps": 10, "likelihood_ratio_clipping": 0.2, "discount": 0.999, "estimate_terminal": false, "critic_network": {"type": "auto", "internal_rnn": false}, "critic_optimizer": {"type": "multi_step", "optimizer": {"type": "adam", "learning_rate": 0.003670157218888348}, "num_steps": 10}, "preprocessing": null, "exploration": 0.0, "variable_noise": 0.0, "l2_regularization": 0.0, "entropy_regularization": 0.01, "name": "ppo_agent", "device": null, "parallel_interactions": 5, "seed": null, "execution": null, "saver": null, "summarizer": null, "recorder": null, "config": null, "internals": {}, "initial_internals": {}}